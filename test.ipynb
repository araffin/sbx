{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Callable, Generator, Optional, Tuple, Union, NamedTuple\n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import jax.numpy as jnp\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3.common.buffers import DictRolloutBuffer, RolloutBuffer\n",
    "from stable_baselines3.common.vec_env import VecNormalize\n",
    "\n",
    "# TODO : see if I add jax info\n",
    "class LSTMStates(NamedTuple):\n",
    "    pi: Tuple\n",
    "    vf: Tuple\n",
    "\n",
    "# TODO : Replaced th.Tensor with jnp.ndarray but might not be true (some as still th Tensors because used in other sb3 functions)\n",
    "# Added lstm states but also dones because they are used in actor and critic\n",
    "class RecurrentRolloutBufferSamples(NamedTuple):\n",
    "    observations: jnp.ndarray\n",
    "    actions: jnp.ndarray\n",
    "    old_values: jnp.ndarray\n",
    "    old_log_prob: jnp.ndarray\n",
    "    advantages: jnp.ndarray\n",
    "    returns: jnp.ndarray\n",
    "    dones: jnp.ndarray\n",
    "    lstm_states: LSTMStates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RecurrentRolloutBuffer(RolloutBuffer):\n",
    "    \"\"\"\n",
    "    Rollout buffer that also stores the LSTM cell and hidden states.\n",
    "\n",
    "    :param buffer_size: Max number of element in the buffer\n",
    "    :param observation_space: Observation space\n",
    "    :param action_space: Action space\n",
    "    :param hidden_state_shape: Shape of the buffer that will collect lstm states\n",
    "        (n_steps, lstm.num_layers, n_envs, lstm.hidden_size)\n",
    "    :param device: PyTorch device\n",
    "    :param gae_lambda: Factor for trade-off of bias vs variance for Generalized Advantage Estimator\n",
    "        Equivalent to classic advantage when set to 1.\n",
    "    :param gamma: Discount factor\n",
    "    :param n_envs: Number of parallel environments\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(       \n",
    "        self,\n",
    "        buffer_size: int,\n",
    "        observation_space: spaces.Space,\n",
    "        action_space: spaces.Space,\n",
    "        # renamed this because I found hidden_state_shape confusing\n",
    "        lstm_state_buffer_shape: Tuple[int, int, int],\n",
    "        device: Union[th.device, str] = \"auto\",\n",
    "        gae_lambda: float = 1,\n",
    "        gamma: float = 0.99,\n",
    "        n_envs: int = 1,\n",
    "    ):  \n",
    "        # TODO : see if I rename this in all the code\n",
    "        self.hidden_state_shape = lstm_state_buffer_shape\n",
    "        self.seq_start_indices, self.seq_end_indices = None, None\n",
    "        super().__init__(buffer_size, observation_space, action_space, device, gae_lambda, gamma, n_envs)\n",
    "\n",
    "    def reset(self):\n",
    "        super().reset()\n",
    "        self.dones = np.zeros((self.buffer_size, self.n_envs), dtype=np.float32)\n",
    "        self.hidden_states_pi = np.zeros(self.hidden_state_shape, dtype=np.float32)\n",
    "        self.cell_states_pi = np.zeros(self.hidden_state_shape, dtype=np.float32)\n",
    "        self.hidden_states_vf = np.zeros(self.hidden_state_shape, dtype=np.float32)\n",
    "        self.cell_states_vf = np.zeros(self.hidden_state_shape, dtype=np.float32)\n",
    "\n",
    "    # def add(self, *args, lstm_states: LSTMStates, **kwargs) -> None:\n",
    "    #     \"\"\"\n",
    "    #     :param hidden_states: LSTM cell and hidden state\n",
    "    #     \"\"\"\n",
    "    #     # TODO : at the moment doesn't work because I didn't create a named tuple for lstm states\n",
    "    #     self.hidden_states_pi[self.pos] = np.array(lstm_states.pi[0].cpu().numpy())\n",
    "    #     self.cell_states_pi[self.pos] = np.array(lstm_states.pi[1].cpu().numpy())\n",
    "    #     self.hidden_states_vf[self.pos] = np.array(lstm_states.vf[0].cpu().numpy())\n",
    "    #     self.cell_states_vf[self.pos] = np.array(lstm_states.vf[1].cpu().numpy())\n",
    "\n",
    "    def add(self, *args, dones, lstm_states, **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        :param hidden_states: LSTM cell and hidden state\n",
    "        \"\"\"\n",
    "        # TODO : at the moment doesn't work because I didn't create a named tuple for lstm states\n",
    "        self.hidden_states_pi[self.pos] = np.array(lstm_states[0][0])\n",
    "        self.cell_states_pi[self.pos] = np.array(lstm_states[0][1])\n",
    "        self.hidden_states_vf[self.pos] = np.array(lstm_states[1][0])\n",
    "        self.cell_states_vf[self.pos] = np.array(lstm_states[1][1])\n",
    "        self.dones[self.pos] = np.array(dones)\n",
    "\n",
    "        super().add(*args, **kwargs)\n",
    "\n",
    "    def get(self, batch_size: Optional[int] = None) -> Generator[RecurrentRolloutBufferSamples, None, None]:\n",
    "        assert self.full, \"Rollout buffer must be full before sampling from it\"\n",
    "\n",
    "        # Prepare the data\n",
    "        if not self.generator_ready:\n",
    "            # hidden_state_shape = (self.n_steps, lstm.num_layers, self.n_envs, lstm.hidden_size)\n",
    "            # swap first to (self.n_steps, self.n_envs, lstm.num_layers, lstm.hidden_size)\n",
    "            for tensor in [\"hidden_states_pi\", \"cell_states_pi\", \"hidden_states_vf\", \"cell_states_vf\"]:\n",
    "                self.__dict__[tensor] = self.__dict__[tensor].swapaxes(1, 2)\n",
    "\n",
    "            # flatten but keep the sequence order\n",
    "            # 1. (n_steps, n_envs, *tensor_shape) -> (n_envs, n_steps, *tensor_shape)\n",
    "            # 2. (n_envs, n_steps, *tensor_shape) -> (n_envs * n_steps, *tensor_shape)\n",
    "            for tensor in [\n",
    "                \"observations\",\n",
    "                \"actions\",\n",
    "                \"values\",\n",
    "                \"log_probs\",\n",
    "                \"advantages\",\n",
    "                \"returns\",\n",
    "                \"dones\",\n",
    "                \"hidden_states_pi\",\n",
    "                \"cell_states_pi\",\n",
    "                \"hidden_states_vf\",\n",
    "                \"cell_states_vf\",\n",
    "                \"episode_starts\",\n",
    "            ]:\n",
    "                self.__dict__[tensor] = self.swap_and_flatten(self.__dict__[tensor])\n",
    "            self.generator_ready = True\n",
    "\n",
    "        # Return everything, don't create minibatches\n",
    "        if batch_size is None:\n",
    "            batch_size = self.buffer_size * self.n_envs\n",
    "\n",
    "        # TODO : Check if this works well \n",
    "        # TODO : Sampling strategy that doesn't allow any mini batch size (must be a multiple of n_envs)\n",
    "        indices = np.arange(self.buffer_size * self.n_envs)\n",
    "\n",
    "        start_idx = 0\n",
    "        while start_idx < self.buffer_size * self.n_envs:\n",
    "            batch_inds = indices[start_idx : start_idx + batch_size]\n",
    "            yield self._get_samples(batch_inds)\n",
    "            start_idx += batch_size\n",
    "\n",
    "\n",
    "    def _get_samples(\n",
    "        self,\n",
    "        batch_inds: np.ndarray,\n",
    "        env: Optional[VecNormalize] = None,\n",
    "    ) -> RecurrentRolloutBufferSamples:\n",
    "        \n",
    "        lstm_states_pi = (\n",
    "            self.hidden_states_pi[batch_inds],\n",
    "            self.cell_states_pi[batch_inds]\n",
    "        )\n",
    "\n",
    "        lstm_states_vf = (\n",
    "            self.hidden_states_vf[batch_inds],\n",
    "            self.cell_states_vf[batch_inds]\n",
    "        )\n",
    "\n",
    "        data = (\n",
    "            self.observations[batch_inds],\n",
    "            self.actions[batch_inds],\n",
    "            self.values[batch_inds].flatten(),\n",
    "            self.log_probs[batch_inds].flatten(),\n",
    "            self.advantages[batch_inds].flatten(),\n",
    "            self.returns[batch_inds].flatten(),\n",
    "            # TODO : Check that\n",
    "            self.dones[batch_inds],\n",
    "            LSTMStates(pi=lstm_states_pi, vf=lstm_states_vf)\n",
    "        )\n",
    "        return RecurrentRolloutBufferSamples(*tuple(map(self.to_torch, data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn \n",
    "\n",
    "import functools\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from stable_baselines3.common.env_util import make_vec_env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_envs = 8\n",
    "n_steps = 128\n",
    "batch_size = 32\n",
    "buffer_size = n_envs * n_steps\n",
    "gamma = 0.99\n",
    "gae_lambda = 0.95\n",
    "hidden_size = 64\n",
    "lstm_state_buffer_shape = (n_steps, n_envs, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"CartPole-v1\"\n",
    "vec_env = make_vec_env(env_id, n_envs=n_envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_buffer = RecurrentRolloutBuffer(\n",
    "    n_steps,\n",
    "    vec_env.observation_space,\n",
    "    vec_env.action_space,\n",
    "    gamma=gamma,\n",
    "    gae_lambda=gae_lambda,\n",
    "    n_envs=n_envs,\n",
    "    lstm_state_buffer_shape=lstm_state_buffer_shape,\n",
    "    device=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 8, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rollout_buffer.cell_states_pi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 8, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rollout_buffer.actions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 8, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rollout_buffer.observations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: a shape = (32, 8, 1), b shape = (32, 8, 4), c shape = (32, 8, 64)\n",
      "Batch 2: a shape = (32, 8, 1), b shape = (32, 8, 4), c shape = (32, 8, 64)\n",
      "Batch 3: a shape = (32, 8, 1), b shape = (32, 8, 4), c shape = (32, 8, 64)\n",
      "Batch 4: a shape = (32, 8, 1), b shape = (32, 8, 4), c shape = (32, 8, 64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_into_batches(a, b, c, batch_size):\n",
    "    n_steps = a.shape[0]\n",
    "    assert n_steps % batch_size == 0, \"n_steps must be a multiple of batch_size\"\n",
    "    \n",
    "    num_batches = n_steps // batch_size\n",
    "    \n",
    "    a_batches = np.split(a, num_batches, axis=0)\n",
    "    b_batches = np.split(b, num_batches, axis=0)\n",
    "    c_batches = np.split(c, num_batches, axis=0)\n",
    "    \n",
    "    return a_batches, b_batches, c_batches\n",
    "\n",
    "# Example usage\n",
    "n_steps = 128\n",
    "n_envs = 8\n",
    "hidden_size = 64\n",
    "batch_size = 32\n",
    "\n",
    "a = np.zeros((n_steps, n_envs, 1))\n",
    "b = np.zeros((n_steps, n_envs, 4))\n",
    "c = np.zeros((n_steps, n_envs, hidden_size))\n",
    "\n",
    "a_batches, b_batches, c_batches = split_into_batches(a, b, c, batch_size)\n",
    "\n",
    "# Check the shapes of the batches\n",
    "for i in range(len(a_batches)):\n",
    "    print(f\"Batch {i+1}: a shape = {a_batches[i].shape}, b shape = {b_batches[i].shape}, c shape = {c_batches[i].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((n_steps, n_envs, 1))\n",
    "b = np.zeros((n_steps, n_envs, 4))\n",
    "c = np.zeros((n_steps, n_envs, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_buffer.full = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_get(buffer: RecurrentRolloutBuffer, batch_size):\n",
    "    data = buffer.get(batch_size)\n",
    "\n",
    "    # Print the name and shape of each item in the data\n",
    "    for name, value in data.items():\n",
    "        print(f\"Name: {name}, Shape: {value.shape}\")\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'generator' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdebug_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m, in \u001b[0;36mdebug_get\u001b[0;34m(buffer, batch_size)\u001b[0m\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m buffer\u001b[38;5;241m.\u001b[39mget(batch_size)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Print the name and shape of each item in the data\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'generator' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "debug_get(rollout_buffer, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "for rollout_data in rollout_buffer.get(batch_size):\n",
    "    print(rollout_data.actions.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
